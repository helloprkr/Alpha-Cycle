# Questions for Cycle 7

## Q1

To ensure we are bridging domains with academic precision, conduct a structured "Technical Trace" search on Recursive Language Models and their connection to inference-time scaling.

**Technical Keywords** (use at least three parallel search queries spanning):
- Recursive architectures: depth-wise computation, iterative refinement, looped transformers, universal transformers
- Dynamical systems: fixed-point iteration, convergence guarantees, attractor dynamics in neural networks
- Computational complexity: adaptive computation time, halting problems in neural networks, Turing completeness
- Adjacent fields: neural ODEs, implicit layers, deep equilibrium models (DEQ)

**Bridging Logic Being Investigated:**
Evidence that recursive/iterative architectural designs provide a principled mechanism for inference-time scaling, where depth of computation emerges dynamically based on problem difficulty rather than being fixed at training time.

**Conceptual Narrative:**
We are investigating whether Recursive Language Models (2512.24601) and related iterative architectures represent a fundamentally different approach to inference scaling than search-based methods (Best-of-N, MCTS). Specifically, whether learned fixed-point iteration can achieve similar compute-optimal tradeoffs while being more parameter-efficient.

**Organization Filter:**
Prioritize contributions from DeepMind, Google Research, Meta FAIR, and researchers working on adaptive computation (Alex Graves, David Duvenaud).

Identify the 5-10 most significant papers from the last two years with high community engagement. For each paper, provide methodology summary, specific contribution to the bridging logic, publication timeframe, and exact link.

Highlight any papers that mention recursive/iterative architectures with emergent connections to reasoning or inference scaling, as these represent potential "missing pieces."

