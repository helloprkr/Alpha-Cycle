{
  "text": "The current consensus in the field of inference-time scaling and chain-of-thought (CoT) reasoning is that we have entered a \"new scaling era\" where computational effort at test-time can effectively substitute for model size. Researchers generally agree that for complex, multi-step tasks like mathematics and coding, the model's performance is a function of the inference-time \"budget\"\u2014how many tokens it can generate or how many search paths it can explore\u2014rather than just the number of pre-training parameters. There is also broad agreement that reinforcement learning (RL) with verifiable rewards (e.g., unit tests or mathematical ground truth) is the most effective way to \"teach\" a model to perform these long, deliberative reasoning chains. However, significant tensions remain regarding the efficiency of these models and whether the generated \"thoughts\" are truly representative of the model's underlying logic.\n\nRelevant Papers on Inference-Time Scaling and Reasoning\n\nA Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?\n, published 9 months ago, consolidates the consensus that test-time scaling is a distinct and vital research direction, categorizing methods like dense-reward-based search and iterative refinement. \nScaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters\n, from a year ago, provides the foundational evidence for the \"compute-optimal\" trade-off between model size and inference time, which has now become a standard framework. \nTowards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models\n, a year ago, details how reinforcement learning has become the consensus method for unlocking these \"System 2\" capabilities in models. \nWhen More is Less: Understanding Chain-of-Thought Length in LLMs\n, published a year ago, highlights a major contested area: the discovery that increasing reasoning length doesn't always lead to better results and can sometimes degrade performance. \nMeasuring Faithfulness in Chain-of-Thought Reasoning\n, from 2 years ago, remains one of the most cited works on an unresolved problem\u2014the fact that a model's stated reasoning steps often don't match the actual logic it uses to arrive at an answer. \nReasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning\n, 7 months ago, explores the contested future of whether reasoning should remain linguistic and human-readable or move into the \"latent\" hidden states of the model for better efficiency. \nCan Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?\n, 10 months ago, addresses the unresolved gap in \"self-correction,\" showing that models often fail to identify their own logical fallacies despite having the capability to reason through the problem initially. \nInference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models\n, a year ago, provides the empirical data that researchers use to debate how to distribute compute across different problem difficulties.\n\nContested and Unresolved Areas\nThe \"Faithfulness\" Gap: A major unresolved debate is whether the chain-of-thought is a \"faithful\" explanation of the model's internal processing. Research has shown that models can be \"right for the wrong reasons\" or can even \"hallucinate\" a logical path that leads to a pre-determined answer, making the reasoning trace a post-hoc justification rather than a true deliberation.\nOptimal Reasoning Length: While some researchers push for longer reasoning chains to solve harder problems, others argue that we are hitting a point of diminishing returns. The \"length-bias\" in training\u2014where models are rewarded for longer answers regardless of quality\u2014remains a contested issue that can lead to \"verbosity\" rather than true intelligence.\nLatent vs. Explicit Reasoning: There is an ongoing debate about whether the \"Chain-of-Thought\" should be explicit text that humans can read. Some propose that the model should \"think\" in hidden vector spaces (latent CoT), which would be much faster but would sacrifice the interpretability that makes CoT so appealing in the first place.\nGeneralization of Reasoning Behaviors: It remains unresolved whether a model trained to reason intensely on mathematical problems can transfer that \"deliberation capability\" to more subjective or creative tasks. Current \"Large Reasoning Models\" excel in objective domains, but their effectiveness in open-ended reasoning is still heavily debated.\nThe Search vs. Generation Trade-off: There is no consensus on the best way to scale compute at test-time. Some favor \"Best-of-N\" sampling (generating many full answers and picking the best), while others argue for more complex tree-search methods (like MCTS) that evaluate the model's path at every step. The computational cost and implementation complexity of these methods are currently a primary bottleneck for deployment.",
  "papers": [
    {
      "title": "A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?",
      "url": "https://alphaxiv.org/abs/2503.24235",
      "arxiv_id": "2503.24235"
    },
    {
      "title": "Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models",
      "url": "https://alphaxiv.org/abs/2503.16419",
      "arxiv_id": "2503.16419"
    },
    {
      "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
      "url": "https://alphaxiv.org/abs/2408.03314",
      "arxiv_id": "2408.03314"
    },
    {
      "title": "Inference-Time Scaling for Generalist Reward Modeling",
      "url": "https://alphaxiv.org/abs/2504.02495",
      "arxiv_id": "2504.02495"
    },
    {
      "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
      "url": "https://alphaxiv.org/abs/2502.03373",
      "arxiv_id": "2502.03373"
    },
    {
      "title": "Self-rewarding correction for mathematical reasoning",
      "url": "https://alphaxiv.org/abs/2502.19613",
      "arxiv_id": "2502.19613"
    },
    {
      "title": "Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning",
      "url": "https://alphaxiv.org/abs/2503.09516",
      "arxiv_id": "2503.09516"
    },
    {
      "title": "Recursive Language Models",
      "url": "https://alphaxiv.org/abs/2512.24601",
      "arxiv_id": "2512.24601"
    },
    {
      "title": "Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models",
      "url": "https://alphaxiv.org/abs/2408.00724",
      "arxiv_id": "2408.00724"
    },
    {
      "title": "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models",
      "url": "https://alphaxiv.org/abs/2501.09686",
      "arxiv_id": "2501.09686"
    },
    {
      "title": "Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models",
      "url": "https://alphaxiv.org/abs/2503.24377",
      "arxiv_id": "2503.24377"
    },
    {
      "title": "A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?",
      "url": "https://alphaxiv.org/abs/2503.24235",
      "arxiv_id": "2503.24235"
    },
    {
      "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
      "url": "https://alphaxiv.org/abs/2408.03314",
      "arxiv_id": "2408.03314"
    },
    {
      "title": "When More is Less: Understanding Chain-of-Thought Length in LLMs",
      "url": "https://alphaxiv.org/abs/2502.07266",
      "arxiv_id": "2502.07266"
    },
    {
      "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
      "url": "https://alphaxiv.org/abs/2502.03373",
      "arxiv_id": "2502.03373"
    },
    {
      "title": "Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning",
      "url": "https://alphaxiv.org/abs/2505.16782",
      "arxiv_id": "2505.16782"
    },
    {
      "title": "Self-rewarding correction for mathematical reasoning",
      "url": "https://alphaxiv.org/abs/2502.19613",
      "arxiv_id": "2502.19613"
    },
    {
      "title": "PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier",
      "url": "https://alphaxiv.org/abs/2506.10406",
      "arxiv_id": "2506.10406"
    },
    {
      "title": "A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?",
      "url": "https://alphaxiv.org/abs/2503.24235",
      "arxiv_id": "2503.24235"
    },
    {
      "title": "Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models",
      "url": "https://alphaxiv.org/abs/2503.24377",
      "arxiv_id": "2503.24377"
    },
    {
      "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
      "url": "https://alphaxiv.org/abs/2408.03314",
      "arxiv_id": "2408.03314"
    },
    {
      "title": "When More is Less: Understanding Chain-of-Thought Length in LLMs",
      "url": "https://alphaxiv.org/abs/2502.07266",
      "arxiv_id": "2502.07266"
    },
    {
      "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
      "url": "https://alphaxiv.org/abs/2502.03373",
      "arxiv_id": "2502.03373"
    },
    {
      "title": "Self-rewarding correction for mathematical reasoning",
      "url": "https://alphaxiv.org/abs/2502.19613",
      "arxiv_id": "2502.19613"
    },
    {
      "title": "Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning",
      "url": "https://alphaxiv.org/abs/2505.16782",
      "arxiv_id": "2505.16782"
    },
    {
      "title": "Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models",
      "url": "https://alphaxiv.org/abs/2408.00724",
      "arxiv_id": "2408.00724"
    },
    {
      "title": "PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier",
      "url": "https://alphaxiv.org/abs/2506.10406",
      "arxiv_id": "2506.10406"
    },
    {
      "title": "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models",
      "url": "https://alphaxiv.org/abs/2501.09686",
      "arxiv_id": "2501.09686"
    },
    {
      "title": "A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?",
      "url": "https://alphaxiv.org/abs/2503.24235",
      "arxiv_id": "2503.24235"
    },
    {
      "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
      "url": "https://alphaxiv.org/abs/2408.03314",
      "arxiv_id": "2408.03314"
    },
    {
      "title": "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models",
      "url": "https://alphaxiv.org/abs/2501.09686",
      "arxiv_id": "2501.09686"
    },
    {
      "title": "When More is Less: Understanding Chain-of-Thought Length in LLMs",
      "url": "https://alphaxiv.org/abs/2502.07266",
      "arxiv_id": "2502.07266"
    },
    {
      "title": "Measuring Faithfulness in Chain-of-Thought Reasoning",
      "url": "https://alphaxiv.org/abs/2307.13702",
      "arxiv_id": "2307.13702"
    },
    {
      "title": "Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning",
      "url": "https://alphaxiv.org/abs/2505.16782",
      "arxiv_id": "2505.16782"
    },
    {
      "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
      "url": "https://alphaxiv.org/abs/2502.19361",
      "arxiv_id": "2502.19361"
    },
    {
      "title": "Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models",
      "url": "https://alphaxiv.org/abs/2408.00724",
      "arxiv_id": "2408.00724"
    }
  ],
  "timestamp": "2026-01-04T01:06:14.559785"
}